@book{Miner2012,
abstract = {MapReduce Design Patterns},
address = {Sebastopol},
author = {Miner, Donald and Shook, Adam},
edition = {First Edit},
editor = {Oram, Andy and Hendrickson, Mike},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/mapreduce\_design\_patterns.pdf:pdf},
isbn = {9781449327170},
pages = {251},
publisher = {O'Reilly},
title = {{MapReduce Design Patterns}},
year = {2012}
}
@article{Hahsler2011,
abstract = {Association rulemining is a popular dataminingmethod available in R as the extension package˜arules. However, mining association rules often results in a very large number of found rules, leaving the analyst with the task to go through all the rules and discover interesting ones. Sifting manually through large sets of rules is time consuming and strenuous. Visualization has a long history of making large data sets better accessible using techniques like selecting and zooming. In this paper we present the R-extension package˜arulesViz which implements several known and novel visualization techniques to explore association rules. With examples we show how these visualization techniques can be used to analyze a data set.},
author = {Hahsler, Michael and Chelluboina, S},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/arulesViz.pdf:pdf},
journal = {R project module},
keywords = {association rules,data mining,visualization},
title = {{Visualizing Association Rules: Introduction to the R-extension Package arulesViz}},
url = {http://www.comp.nus.edu.sg/~zhanghao/project/visualization/[2010]arulesViz.pdf},
year = {2011}
}
@article{Woo,
author = {Woo, Jongwook},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/Apriori\_MapReduce.pdf:pdf},
keywords = {11-13,algorithms with map,apriori algorithm,association rule,cloud computing,data mining,hadoop,map,presents market basket analysis,reduce,which proposes the algorithm,woo et al},
title = {{Apriori-Map / Reduce Algorithm}}
}
@inproceedings{Yang2010,
abstract = {As association rules widely used, it needs to study many problems, one of which is the generally larger and multi-dimensional datasets, and the rapid growth of the mount of data. Single-processor's memory and CPU resources are very limited, which makes the algorithm performance inefficient. Recently the development of network and distributed technology makes cloud computing a reality in the implementation of association rules algorithm. In this paper we describe the improved Apriori algorithm based on MapReduce mode, which can handle massive datasets with a large number of nodes on Hadoop platform.},
author = {Yang, Xin Yue and Liu, Zhen and Fu, Yan},
booktitle = {Proceedings - 3rd International Conference on Information Sciences and Interaction Sciences, ICIS 2010},
doi = {10.1109/ICICIS.2010.5534718},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/Apriori\_Hadoop.pdf:pdf},
isbn = {9781424473854},
keywords = {Apriori,Association rules,Hadoop,KDD,MapReduce},
pages = {99--102},
title = {{MapReduce as a programming model for association rules algorithm on Hadoop}},
year = {2010}
}
@article{Gedik2008,
abstract = {In this paper, we present Spade − the System S declarative stream processing engine. System S is a large-scale, dis- tributed data stream processing middleware under develop- ment at IBM T. J.Watson Research Center. As a front-end for rapid application development for System S, Spade pro- vides (1) an intermediate language for flexible composition of parallel and distributed data-flow graphs, (2) a toolkit of type-generic, built-in stream processing operators, that sup- port scalar as well as vectorized processing and can seam- lessly inter-operate with user-defined operators, and (3) a rich set of stream adapters to ingest/publish data from/to outside sources. More importantly, Spade automatically brings performance optimization and scalability to System S applications. To that end, Spade employs a code genera- tion framework to create highly-optimized applications that run natively on the Stream Processing Core (SPC), the exe- cution and communication substrate of System S, and take full advantage of other System S services. Spade allows de- velopers to construct their applications with fine granular stream operators without worrying about the performance implications that might exist, even in a distributed system. Spade’s optimizing compiler automatically maps applica- tions into appropriately sized execution units in order to minimize communication overhead, while at the same time exploiting available parallelism. By virtue of the scalability of the System S runtime and Spade’s effective code genera- tion and optimization, we can scale applications to a large number of nodes. Currently, we can run Spade jobs on ≈ 500 processors within more than 100 physical nodes in a tightly connected cluster environment. Spade has been in use at IBM Research to create real-world streaming applications, ranging from monitoring financial market feeds to radio telescopes to semiconductor fabrication lines. Categories},
author = {Gedik, B ( 1 ) and Andrade, H ( 1 ) and Wu, K.-L. ( 1 ) and Yu, P S ( 2 ) and Doo, M ( 3 )},
doi = {10.1145/1376616.1376729},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/gedik\_sigmod\_2008.pdf:pdf},
isbn = {9781605581026},
issn = {07308078},
journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
keywords = {Distributed Data Stream Processing},
number = {SIGMOD 2008: Proceedings of the ACM SIGMOD International Conference on Management of Data 2008},
pages = {1123--1134},
title = {{SPADE: The system S declarative stream processing engine.}},
url = {https://access.korea.ac.kr/link.n2s?url=http://search.ebscohost.com/login.aspx?direct=true\&db=edselc\&AN=edselc.2-52.0-55649105542\&lang=ko\&site=eds-live\&scope=site},
year = {2008}
}
@article{Andrade2011,
abstract = {High-performance stream processing is critical in many sense-and-respond application domains—from environmental monitoring to algorithmic trading. In this paper, we focus on language and runtime support for improving the performance of sense-and-respond applications in processing data from high-rate live streams. The central tenets of this work are the programming model, the workload splitting mechanisms, the code generation framework, and the underlying System S middleware and Spade programming model. We demonstrate considerable scalability behavior coupled with low processing latency in a real-world financial trading application.},
author = {Andrade, H and Gedik, B and Wu, K.-L. and Yu, P S},
doi = {http://dx.doi.org/10.1016/j.jpdc.2010.08.007},
isbn = {0743-7315},
issn = {0743-7315},
journal = {Journal of Parallel and Distributed Computing},
keywords = {Data stream processing,Scale-up strategies,Split/aggregate/join architectural pattern,Workload balancing},
number = {2},
pages = {145--156},
title = {{Processing high data rate streams in System S}},
url = {http://www.sciencedirect.com/science/article/pii/S074373151000167X},
volume = {71},
year = {2011}
}
@book{Few2006,
abstract = {Published January 2006, 223 pages. SUMMARY: Dashboards have become popular in recent years as uniquely powerful tools for communicating important information at a glance. Although dashboards are potentially powerful, this potential is rarely realized. The greatest display technology in the world won't solve this if you fail to use effective visual design. And if a dashboard fails to tell you precisely what you need to know in an instant, you'll never use it, even if it's filled with cute gauges, meters, and traffic lights. Don't let your investment in dashboard technology go to waste. This book will teach you the visual design skills you need to create dashboards that communicate clearly, rapidly, and compellingly. "Information Dashboard Design" will explain how to: Avoid the thirteen mistakes common to dashboard design Provide viewers with the information they need quickly and clearly Apply what we now know about visual perception to the visual presentation of information Minimize distractions, cliches, and unnecessary embellishments that create confusion Organize business information to support meaning and usability Create an aesthetically pleasing viewing experience Maintain consistency of design to provide accurate interpretation Optimize the power of dashboard technology by pairing it with visual effectiveness Stephen Few has over 20 years of experience as an IT innovator, consultant, and educator. As Principal of the consultancy Perceptual Edge, Stephen focuses on data visualization for analyzing and communicating quantitative business information. He provides consulting and training services, speaks frequently at conferences, and teaches in the MBA program at the University of California in Berkeley. He is also the author of "Show Me the Numbers: Designing Tables and Graphs to Enlighten." Visit his website at www.perceptualedge.com.},
author = {Few, Stephen},
booktitle = {The effective visual communication of data Sebastopol},
file = {:C$\backslash$:/Users/Jake/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Few - 2006 - Information Dashboard Design.pdf:pdf},
isbn = {0596100167},
pages = {223},
title = {{Information Dashboard Design}},
url = {http://proquest.safaribooksonline.com/0596100167?suggested=top},
year = {2006}
}
@article{Tufle1983,
abstract = {Tufte, E. R., \& Graves-Morris, P. R. (1983). The visual display of quantitative information (Vol. 2). Cheshire, CT: Graphics press.},
author = {Tufte, E},
isbn = {978-0961392147},
journal = {CT Graphics, Cheshire},
title = {{The Visual Display of Quantitative Information}},
url = {http://www.colorado.edu/UCB/AcademicAffairs/ArtsSciences/geography/foote/maps/assign/reading/TufteCoversheet.pdf},
year = {2001}
}
@misc{,
keywords = {Information Visualization, Information Systems Suc},
title = {{A Structured Review of Information Visualization Success Measurement}},
url = {http://ewic.bcs.org/upload/pdf/ewic\_hci10\_paper1.pdf},
urldate = {2015-03-03}
}
@inproceedings{Wattenberg2008,
abstract = {We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A word tree is a graphical version of the traditional "keyword-in-context" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.},
author = {Wattenberg, Martin and Vi\'{e}gas, Fernanda B.},
booktitle = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Case study,Concordance,Document visualization,Information retrieval,Many eyes,Search,Text visualization},
number = {6},
pages = {1221--1228},
pmid = {18988967},
title = {{The word tree, an interactive visual concordance}},
volume = {14},
year = {2008}
}
@book{Deleuze1987,
abstract = {The two of us wrote Anti-Oedipus together. Since each of us was several, there was already quite a crowd. Here we have made use of everything came within range, what was closest as well as farthest away. We assigned clever pseudonyms to prevent recognition. Why have we},
author = {Deleuze, Gilles and Guattari, PF and Guattari, Felix},
booktitle = {Writing},
chapter = {1},
number = {4},
pages = {151--169},
pmid = {12766771},
publisher = {University of Minnesota Press},
title = {{A thousand plateaus: Capitalism and schizophrenia}},
url = {http://www.jstor.org/stable/203963?origin=crossref$\backslash$nhttp://www.amazon.com/dp/0816614024$\backslash$nhttp://books.google.com/books?hl=en\&lr=\&id=C948Tsr72woC\&oi=fnd\&pg=PR9\&dq=a+thousand+plateaus:+capitalism+and+schizophrenia\&ots=9kIrnHqEGg\&sig=geid0WbkPt-qSY-Ub7WB7f\_eK5w},
volume = {19},
year = {1987}
}
@inproceedings{Olston2008,
abstract = {There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where inno- vation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, o er a solution, but are usually prohibitively ex- pensive at this scale. Besides, many of the people who ana- lyze this data are entrenched procedural programmers, who nd the declarative, SQL style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hard- ware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse. We describe a new language called Pig Latin that we have designed to t in a sweet spot between the declarative style of SQL, and the low-level, procedural style of map-reduce. The accompanying system, Pig, is fully implemented, and compiles Pig Latin into physical plans that are executed over Hadoop, an open-source, map-reduce implementation. We give a few examples of how engineers at Yahoo! are using Pig to dramatically reduce the time required for the develop- ment and execution of their data analysis tasks, compared to using Hadoop directly. We also report on a novel debugging environment that comes integrated with Pig, that can lead to even higher productivity gains. Pig is an open-source, Apache-incubator project, and available for general use.},
author = {Olston, Christopher and Reed, Benjamin and Srivastava, Utkarsh and Kumar, Ravi and Tomkins, Andrew},
booktitle = {Proceedings of the 2008 ACM SIGMOD international conference on Management of data - SIGMOD '08},
doi = {10.1145/1376616.1376726},
isbn = {9781605581026},
keywords = {H.2.3 Database Management: Languages},
pages = {1099},
title = {{Pig latin}},
url = {http://infolab.stanford.edu/~olston/publications/sigmod08.pdf$\backslash$nhttp://portal.acm.org/citation.cfm?doid=1376616.1376726},
year = {2008}
}
@inproceedings{Olston2008a,
abstract = {There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where inno- vation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, offer a solution, but are usually prohibitively ex- pensive at this scale. Besides, many of the people who ana- lyze this data are entrenched procedural programmers, who find the declarative, SQL style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hard- ware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse. We describe a new language called Pig Latin that we have designed to fit in a sweet spot between the declarative style of SQL, and the low-level, procedural style of map-reduce. The accompanying system, Pig, is fully implemented, and compiles Pig Latin into physical plans that are executed over Hadoop, an open-source, map-reduce implementation. We give a few examples of how engineers at Yahoo! are using Pig to dramatically reduce the time required for the develop- ment and execution of their data analysis tasks, compared to using Hadoop directly. We also report on a novel debugging environment that comes integrated with Pig, that can lead to even higher productivity gains. Pig is an open-source, Apache-incubator project, and available for general use.},
author = {Olston, Christopher and Reed, Benjamin and Srivastava, Utkarsh and Kumar, Ravi and Tomkins, Andrew},
booktitle = {Proceedings of the 2008 ACM SIGMOD international conference on Management of data - SIGMOD '08},
doi = {10.1145/1376616.1376726},
isbn = {978-1-60558-102-6},
issn = {07308078},
keywords = {dataflow language,pig latin},
pages = {1099},
title = {{Pig Latin: A Not-So-Foreign Language for Data Processing}},
year = {2008}
}
@inproceedings{Kunegis2013,
author = {Kunegis, J\'{e}r\^{o}me},
booktitle = {WWW 2013 Companion},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/kunegis-koblenz-network-collection.pdf:pdf},
isbn = {9781450320382},
keywords = {network analysis,web observatory},
title = {{KONECT - The Koblenz Network Collection}},
year = {2013}
}
@misc{KONECT,
author = {KONECT},
title = {{Konect network dataset}},
url = {http://konect.uni-koblenz.de/}
}
@inproceedings{Didimo2011,
address = {Konstanz},
author = {Didimo, Walter and Liotta, Giuseppe and Romeao, Salvatore},
booktitle = {Graph Drawing 2010 Revised Selected Papers},
editor = {Brandes, Ulrik and Cornelsen, Sabine},
pages = {165--176},
publisher = {Springer Berlin Heidelberg},
title = {{Topology-Driven Force-Directed Algorithms}},
year = {2011}
}
@inproceedings{Islam2012,
abstract = {Hadoop is a massively scalable parallel computation platform capable of running hundreds of jobs concurrently, and many thousands of jobs per day. Managing all these computations demands for a workflow and scheduling system. In this paper, we identify four indispensable qualities that a Hadoop workflow management system must fulfill namely Scalability, Security, Multi-tenancy, and Operability. We find that conventional workflow management tools lack at least one of these qualities, and therefore present Apache Oozie, a workflow management system specialized for Hadoop. We discuss the architecture of Oozie, share our production experience over the last few years at Yahoo, and evaluate Oozie's scalability and performance.},
author = {Islam, Mohammad and Huang, Angelo K. and Battisha, Mohamed and Chiang, Michelle and Srinivasan, Santhosh and Peters, Craig and Neumann, Andreas and Abdelnur, Alejandro},
booktitle = {Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies - SWEET '12},
pages = {1--10},
publisher = {ACM Press},
title = {{Oozie: towards a scalable workflow management system for Hadoop}},
url = {http://dx.doi.org/10.1145/2443416.2443420},
year = {2012}
}
@book{Robbins2005,
address = {Hoboken},
author = {Robbins, Naomi},
pages = {49},
publisher = {John Wiley \& Sons},
title = {{Creating More Effective Graphs}},
year = {2005}
}
@article{Anscombe1973,
author = {Anscombe, F J},
doi = {10.1080/00031305.1973.10478966},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/anscombe1973.pdf:pdf},
isbn = {00031305},
issn = {0003-1305},
journal = {The American Statistician},
number = {1},
pages = {17--21},
title = {{Graphs in Statistical Analysis}},
url = {http://www.sjsu.edu/faculty/gerstman/StatPrimer/anscombe1973.pdf},
volume = {27},
year = {1973}
}
@article{Shoresh2012,
author = {Shoresh, Noam and Wong, Bang},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/nmeth.1829.pdf:pdf},
journal = {Nature Methods},
number = {1},
pages = {5},
title = {{Points of view: Data exploration}},
volume = {9},
year = {2012}
}
@inproceedings{Klasky2011,
abstract = {need for new I/O system for extreme-scale computing: 1)service oriented; 2)in situ processing!; 3) data staging;4) data management; 5) monitoring; 6) usability of I/O optimizations; 7) data formats},
author = {Klasky, Scott and Abbasi, Hasan and Logan, Jeremy and Parashar, Manish and Schwan, Karsten and Shoshani, Arie and Wolf, Matthew and Sean, Ahern and Altintas, Ilkay and Bethel, Wes and Luis, Chacon and Chang, CS and Chen, Jackie and Childs, Hank and Cummings, Julian and Docan, Ciprian and Eisenhauer, Greg and Ethier, Stephane and Grout, Ray and Lakshminarasimhan, Sriram and Lin, Zhihong and Liu, Qing and Ma, Xiaosong and Moreland, Kenneth and Pascucci, Valerio and Podhorszki, Norbert and Samatova, Nagiza and Schroeder, Will and Tchoua, Roselyne and Tian, Yuan and Vatsavai, Raju and Wu, John and Yu, Weikuan and Zheng, Fang},
booktitle = {SciDAC Conference},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/scidac11-adios-insitu.pdf:pdf},
title = {{In Situ Data Processing for Extreme-Scale Computing}},
url = {http://pasl.eng.auburn.edu/pubs/scidac11-adios-insitu.pdf},
year = {2011}
}
@article{Battre2010,
abstract = {We present a parallel data processor centered around a programming model of so called Parallelization Contracts (PACTs) and the scalable parallel execution engine Nephele [18]. The PACT programming model is a generalization of the well-known map/reduce programming model, extending it with further second-order functions, aswellaswith Output Contracts that give guarantees about the behavior of a func- tion. We describe methods to transform a PACT program into a data flow for Nephele, which executes its sequential building blocks in parallel and deals with communication, synchronization and fault tolerance. Our definition of PACTs allows to apply several types of optimizations on the data flow during the transformation. Thesystemasawholeisdesignedtobeasgenericas(and compatible to)map/reduce systems, while overcoming several of their major weaknesses: 1) The functions map and reduce alone are not sufficient to express many data processing tasks both naturally and efficiently. 2) Map/reduce ties a program to a single fixed execution strategy, which is robust but highly suboptimal for many tasks. 3) Map/reduce makes no assumptions about the behavior of the functions. Hence, it offers only very limited optimization opportunities. With a set of examples and experiments, we illustrate how our system is able to naturally represent and efficiently execute several tasks that do not fit the map/reduce model well.},
author = {Battr\'{e}, Dominic and Ewen, Stephan and Hueske, Fabian and Kao, Odej},
doi = {http://doi.acm.org/10.1145/1807128.1807148},
file = {:C$\backslash$:/Users/Jake/Dropbox/Thesis/References/paper\_nephelePACTs\_2010.pdf:pdf},
isbn = {9781450300360},
journal = {ACM Symposium on Cloud Computing},
keywords = {cloud computing,map reduce,web-scale data},
pages = {119--130},
title = {{Nephele / PACTs : A Programming Model and Execution Framework for Web-Scale Analytical Processing Categories and Subject Descriptors}},
url = {http://doi.acm.org/10.1145/1807128.1807148$\backslash$nhttp://dl.acm.org/citation.cfm?id=1807148},
year = {2010}
}
@article{Amsterdamer2011,
abstract = {Workflow provenance typically assumes that each module is a "black-box", so that each output depends on all inputs (coarse-grained dependencies). Furthermore, it does not model the internal state of a module, which can change between repeated executions. In practice, however, an output may depend on only a small subset of the inputs (fine-grained dependencies) as well as on the internal state of the module. We present a novel provenance framework that marries database-style and workflow-style provenance, by using Pig Latin to expose the functionality of modules, thus capturing internal state and fine-grained dependencies. A critical ingredient in our solution is the use of a novel form of provenance graph that models module invocations and yields a compact representation of fine-grained workflow provenance. It also enables a number of novel graph transformation operations, allowing to choose the desired level of granularity in provenance querying (ZoomIn and ZoomOut), and supporting "what-if" workflow analytic queries. We implemented our approach in the Lipstick system and developed a benchmark in support of a systematic performance evaluation. Our results demonstrate the feasibility of tracking and querying fine-grained workflow provenance.},
archivePrefix = {arXiv},
arxivId = {1201.0231v1},
author = {Amsterdamer, Yael and Davidson, Susan B and Deutch, Daniel and Milo, Tova and Stoyanovich, Julia and Tannen, Val},
eprint = {1201.0231v1},
file = {:C$\backslash$:/Users/Jake/Downloads/p346-amsterdamer.pdf:pdf},
issn = {2150-8097},
journal = {Proceedings of the VLDB Endowment},
number = {4},
pages = {346--357},
title = {{Putting Lipstick on Pig : Enabling Database-style Workflow Provenance}},
url = {http://dl.acm.org/citation.cfm?id=2095693},
volume = {5},
year = {2011}
}
@article{Pauw2010,
abstract = {Stream processing is a new computing paradigm that enables con- tinuous and fast analysis of massive volumes of streaming data. Debugging streaming applications is not trivial, since they are typically distributed across multiple nodes and handle large amounts of data. Traditional debugging tech- niques like breakpoints often rely on a stop-the-world approach, which may be useful for debugging single node applications, but insufficient for streaming applications. We propose a new visual and analytic environment to support de- bugging, performance analysis, and troubleshooting for stream processing ap- plications. Our environment provides several visualization methods to study, characterize, and summarize the flow of tuples between stream processing op- erators. The user can interactively indicate points in the streaming application from where tuples will be traced and visualized as they flow through different operators, without stopping the application. To substantiate our discussion, we also discuss several of these features in the context of a financial engineering application.},
author = {Pauw, Wim De and Leţia, M and Gedik, B and Andrade, Henrique},
file = {:C$\backslash$:/Users/Jake/Downloads/2010 De Pauw.pdf:pdf},
journal = {Runtime Verification},
keywords = {debugging,performance,streaming applications,visualization},
pages = {18--35},
title = {{Visual debugging for stream processing applications}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-16612-9\_3},
year = {2010}
}
@article{Few2007,
author = {Few, Stephen},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/save\_the\_pies\_for\_dessert.pdf:pdf},
journal = {Visual Business Intelligence Newsletter},
keywords = {Information Dashboard Design,Perceptual Edge,Pie chart,Show Me the Numbers,Stephen Few,Visual Business Intelligence Newsletter,graph design,pie charts,pop charts,table design},
pages = {1--14},
title = {{Save the Pies for Dessert}},
url = {http://www.perceptualedge.com/articles/visual\_business\_intelligence/save\_the\_pies\_for\_dessert.pdf},
year = {2007}
}
@article{Tufte1991,
abstract = {A remarkable range of examples for the idea of visual thinking, with beautifully printed pages. A real treat for all who reason and learn by means of images. - Rudolf Arnheim},
author = {Tufte, Edward},
doi = {10.1213/00000539-199103000-00040},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/tufte, edward - envisioning information.pdf:pdf},
isbn = {0961392118},
issn = {0003-2999},
journal = {Bulletin of the Medical Library Association},
number = {3},
pages = {346--348},
pmid = {3895920},
title = {{Envisioning Information}},
volume = {79},
year = {1991}
}
@inproceedings{VanHam2009,
abstract = {We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.},
author = {{Van Ham}, Frank and Wattenberg, Martin and Vi\'{e}gas, Fernanda B.},
booktitle = {IEEE Transactions on Visualization and Computer Graphics},
doi = {10.1109/TVCG.2009.165},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/phrase-net-rev5.pdf:pdf},
isbn = {1077-2626 VO - 15},
issn = {10772626},
keywords = {Text visualization,natural language processing,semantic net,tag cloud},
number = {6},
pages = {1169--1176},
pmid = {19834186},
title = {{Mapping text with phrase nets}},
volume = {15},
year = {2009}
}
@article{Wickham2006,
author = {Wickham, Hadley},
file = {:C$\backslash$:/Users/Jake/Documents/Thesis References/ggplot.pdf:pdf},
journal = {American Statistical Association 2006 Proceedings of the Section on Statistical Graphics},
keywords = {graphics; framework},
pages = {1--8},
title = {{An Implemetation of the Grammar of Graphics in \{R\}: ggplot}},
year = {2006}
}
