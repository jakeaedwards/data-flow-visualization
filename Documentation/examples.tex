\chapter{Examples}
\label{sec:examples}
\INITIAL{T}{o construct useful examples} it is crucial that we consider both scenarios which are both likely to be encountered during a broad range of analysis scenarios, and specific enough to address the basic issues of visualizing unique types of data. The following use-cases discuss the aims of the analysis being suggested and how that relates to the anticipated patterns and visualizations discussed in the previous chapters. The generation of visualizations from an analyst's perspective is discussed, but details of how these are generated are left for Chapter 6.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Census Data Analysis}
\label{sec:census}
\INITIAL{T}{he first case we will examine} is an analysis of data extracted from the United States census bureau database. This data set in particular has become a standard example data set used in statistical outlier detection, and particularly in the application and development of machine learning algorithms. It was extracted from the database in 1994, is available online in the University of California Irvine's machine learning repository \cite{Blake1998}, and was first used in publication in the paper "Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid"\cite{Kohavi1996} in 1996. 

\paragraph{Demographic Data}
Demographic data provides a perfect example for most big data type analyses because it can be used in many fields with very little alteration to the methods applied. In social science or political research the study of individuals as would appear in a census is immediately applicable with obvious potential gains stemming from the results of the  analysis. Though the census itself may not necessarily be as interesting in the corporate world, capturing traits of individuals in a census is analogous to maintaining a database of employees or customers. Likewise any field which analyses individuals, whether they be medical patients or users of a mobile application, will apply similar if not identical methods to a data set of approximately the same semantic structure. 

\paragraph{Conditional Split}
In a machine learning context, this data set is used to predict whether the income of an individual exceeds \$50,000 per year. Because this data would normally be partitioned into a training and testing set for use with a predictive model such as a naive Bayes classifier or neural network, it includes a field with the correct response so that testing results can be verified. Thus, we already know whether an individual in the dataset falls into one of the two possible categories (>50K, <=50K) without analysis. We can therefore ignore any prediction and assume a much simpler data flow, a basic conditional split on the category field. If categorical demographic data is to be analyzed in an in-situ context, a reasonable question from an analyst who has not been able to prepare or pre-examine the data set in any rigorous way would be what proportion of records exist across the given categories. In cases where analysts have significant subject matter expertise, a simple visualization of these proportions would be enough to confirm expected results, show an unexpected reality, or imply an error in the quality of data or in the analysis methods.

\paragraph{Split Computation}
The actual MapReduce job for such a task is very simple, and consists of an implementation of the numerical summarization pattern. Firstly, the field containing the income categorization flag is extracted from the data source. Then, a flat map function returns a tuple for each record containing the income category and and the integer 1. Following this, we simply reduce by summing the "1" field across each category to determine the totals for each. This is analogous to the standard word count example paired with most MapReduce systems. To perform the visualization, only four lines of code must be added by the author of the analysis task, as seen below:

\paragraph{}
\begin{lstlisting}[language=Java,showspaces=false,showstringspaces=false,breaklines=true, breakatwhitespace=true]
        Visualizer visualizer = new Visualizer();
        InSituCollector totalsCollector = new InSituCollector(visualizer);
        totalsCollector.collect(1, totals, String.class, Integer.class);
        visualizer.visualizeBarChart(1, "Census Income Categories", "Category", "Count");
\end{lstlisting}

\paragraph{Visualization Code}
The first two lines create a visualizer and in-situ collector, respectively. The visualizer class doesn't require any parameters to be instantiated, and the collector requires a reference to the visualizer class so that it has somewhere to send collected data. The second two lines of code perform all of the actual work in visualizing the data from this flow. The collect method of the collector is called in the third line and accepts three arguments in this case. The first argument is an integer identifier for the collected data set, which can then be referenced later in order to specify which data is to be visualized. The second argument is a data set object from the Flink analysis task in question, and the remaining arguments are class objects representing the fields contained in the data set "totals", in order. In the last line, the actual visualization function is called from the visualizer. The first, and only required, argument to this function is the identifier of the data set which we collected earlier. Additionally, in this case three string arguments have been provided, which apply a title and axis labels to the resulting visualization. The resulting bar chart is shown in Figure \ref{fig:conditional}.     

%%%%%%%%%%%%%%%%%%
\begin{figure}
	\centering
	\label{fig:conditional}
	\includegraphics[scale=0.7]{Census_Conditional.png}
	\caption{A bar chart showing census income category proportions}
\end{figure}
%%%%%%%%%%%%%%%%%%

\paragraph{Bar Chart}
As discussed in Chapter 3, a bar chart is the most appropriate chart to be applied in the case of category comparison. We can see immediately when looking at Figure \ref{fig:conditional} that those who make less than \$50,000 are outnumbered by a rate of roughly 3:1 (in fact, the true proportion is 3.15:1). Given the limited input that is provided in the call to the visualizer, we achieve adequate results in the design of the chart. The labeling is clear and well formatted given the provided input. Even without the provision of labels from the method call, someone with an approximately accurate estimate about the outcome would be able to read the chart without labels. Of course, because we cannot know before the  program is run what values to expect, there are some limitations to the way in which we format the results. A good example of this is the x axis. If we desired axis value differences of less or more than 5,000 or a starting point other than 0 it is not a trivial change to make. However, because the purpose of this type of visualization is focused on getting a sense of data in the in-situ context rather than performing detailed visual analysis, it could be argued that such changes are unnecessary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Network Analysis}
\label{sec:network}
\INITIAL{N}{etwork data sets are ubiquitous} in many fields, as was briefly discussed in Chapter 3. We will examine some of the basic analyses identified by the KONECT project \cite{Kunegis2013}, and use one of the datasets they have provided in order to enable simple comparison of results and reproduction of visualizations which have been proven useful.

\paragraph{Les Misérables}
Firstly, we will examine a graph representing data extracted from the novel "Les Misérables" by Victor Hugo. Representing only a single work rather than a corpus of texts, this data set is relatively small. This enables us to examine the features of network data in general, and also those visualizations which relate to layout and will only be applicable with sufficiently few nodes. Within this network, each node represents a character in the narrative of the plot, and the edges represent a meeting between two characters. Each edge is weighted with an integer, representing the number of distinct times that the characters appear together. In summary, the graph is undirected and weighted.

%%%%%%%%%%%%%%%%%% 
\begin{figure}
	\centering
	\begin{minipage}{0.45\textwidth}
		\centering
		\label{fig:edgeweightslesmis}
		\includegraphics[scale=0.5]{edge_weights_lesmis_inverted.png}
		\caption{A bar chart showing edge weights in the Les Miserables network}
	\end{minipage}\hfill
	\begin{minipage}{0.45\textwidth}
		\centering
		\label{fig:edgeweightskonect}
		\includegraphics[scale=0.9]{konect_lesmis_edgeweight.png}
		\caption{A bar chart showing edge weights from KONECT}
	\end{minipage}
\end{figure}
%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%% 
\begin{figure}
	\centering
	\begin{minipage}{0.45\textwidth}
		\centering
		\label{fig:edgeweightslesmis}
		\includegraphics[scale=0.5]{degree_freq_lesmis.png}
		\caption{A scatter plot showing degree frequency in the Les Miserables network}
	\end{minipage}\hfill
	\begin{minipage}{0.45\textwidth}
		\centering
		\label{fig:edgeweightskonect}
		\includegraphics[scale=0.9]{konect_lesmis_degdist.png}
		\caption{A scatter plot showing degree frequency from KONECT}
	\end{minipage}
\end{figure}
%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classification}
\label{sec:classification}
\INITIAL{A}{s one of the core tasks in exploratory data mining} classification provides a scenario which would very likely rely on in-situ data processing. The data set to be examined is the "Iris Plants Database" \cite{Fisher1936} which first appeared in 1936 as an example of discriminant analysis. It consists of four measurements: the width and length of both the petal and sepal of three different species of iris. Based on its initial use in developing a model which distinguished different iris species, it has since been used as a standard test case for various classification techniques. If this data is examined from the perspective of an analyst with limited prior knowledge of the features of the data (apart from the species included) visualizations can be used to limit potential classification methods. 

\paragraph{Scatter Plot}
A basic visualization of this data such as in Figure \ref{fig:sepal_clustering} immediately indicates that there are two distinct clusters in the data set.  Additionally, it can be seen that some of the points in the scatter plot have darker colouring than others. This indicates identical records in the source data set, with darker points indicating more duplicates. Because axis scaling is based on the values present in the data set rather than some pre-determined range, they are well distributed across the layout of the plot at the expense of what is arguably an unorthodox axis origin. The two cluster shown isolate on of the three species in the data set, but do not separate the remaining two visually. This is somewhat interesting, but is limited in that only two variables are seen at once, perhaps hiding some relationship that exists between another combination of our iris features. As we expect three classes of data within the set, it follows that we should hope to see three approximately separate clusters in one such comparison.

%%%%%%%%%%%%%%%%%%
\begin{figure}
	\centering
	\label{fig:sepal_clustering}
	\includegraphics[scale=0.7]{sepal_clustering.png}
	\caption{A scatterplot showing iris sepal data}
\end{figure}
%%%%%%%%%%%%%%%%%%

\paragraph{Matrix Plot}
A standard method for examining the relationship between multiple variables is to simply visualize each combination in a grid, in this case as a scatter plot matrix. Such a visualization can be seen in Figure \ref{fig:scatterplot_matrix}. While the fine grain details in such a visualization are somewhat more obscured in comparison to the individual scatter plot, we can now easily obtain an approximate idea of the relationships between each variable in our data set. The matrix is composed of a square grid with dimensions equal to the number of variables to be compared, with the main diagonal of the grid representing the variables themselves. The remaining squares in the matrix are filled with scatter plots; where the x-axis of each represents the variable with which it shares a column, and the y-axis the variable with which it shares a row. The relative size of the plots will of course be scaled to the number of variables present, but may be impractical with larger numbers of variables. The labeling and titles are less important here as we are focused on broad visual patterns more than specific statistic, similar to the case with spark lines. Also, because labels for the variables do not exist in the Flink data set being analyzed in this case, placeholder names are given to each variable. It is assumed that either the user is aware of the order in which they were provided to the collector and can infer their semantic meaning, or that the specific variable names themselves are unimportant relative to the patterns exhibited.

\paragraph{Classification Method}
In this case, we can see that across all plots in the matrix only two clearly demarcated clusters exist. This means that regardless of which variables are chosen for comparison, we are unlikely to be able to separate all three species of iris using a simple linear method. An analyst faced with such a figure would be likely to apply a supervised learning method if at all possible, or perhaps a more complex unsupervised method such as a linear principal component analysis. 

%%%%%%%%%%%%%%%%%%
\begin{figure}
	\centering
	\label{fig:scatterplot_matrix}
	\includegraphics[scale=0.7]{scatterplot_matrix.png}
	\caption{A scatterplot matrix showing iris data across all variables}
\end{figure}
%%%%%%%%%%%%%%%%%%